{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process antibody hashtag reads and assign to cells\n",
    "(Pre-processing step for Scanpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Self defined functions for identifying cell antibody hashtags\n",
    "def findAb(ftTsv):\n",
    "    AbDict = {}\n",
    "    with open(ftTsv, \"r\") as fin:\n",
    "        rfin = csv.reader(fin, delimiter=\"\\t\")\n",
    "        rowN = 0\n",
    "        for row in rfin:\n",
    "            rowN += 1\n",
    "            if row[2] == \"Antibody Capture\":\n",
    "                AbDict[rowN] = row[0]\n",
    "    return(AbDict)\n",
    "\n",
    "def cellAbReads(ftTsv, mtxMtx):\n",
    "    outName = \"Cells_hashTags.csv\"\n",
    "    abDict = findAb(ftTsv)\n",
    "    with open(mtxMtx, \"r\") as fin:\n",
    "        with open(outName, \"w\") as fout:\n",
    "            rfin = csv.reader(fin, delimiter=\" \")\n",
    "            wfout = csv.writer(fout, delimiter=\",\")\n",
    "            wfout.writerow([\"Cell\"] + list(abDict.values()))\n",
    "            \n",
    "            next(rfin)\n",
    "            next(rfin)\n",
    "            next(rfin)\n",
    "            step = 1\n",
    "            outRow = [1] + [0 for x in abDict]\n",
    "            for row in rfin:\n",
    "                cellN = int(row[1])\n",
    "                if cellN != step:\n",
    "                    wfout.writerow(outRow)\n",
    "                    step = cellN\n",
    "                    outRow = [row[1]] + [0 for x in abDict]\n",
    "                if int(row[0]) in list(abDict.keys()):\n",
    "                    abIdx = list(abDict.keys()).index(int(row[0])) + 1\n",
    "                    outRow[abIdx] = int(row[2])\n",
    "            wfout.writerow(outRow)\n",
    "\n",
    "def cellType(cellTag):\n",
    "    outfile = \"Cells_Type.csv\"\n",
    "    with open(cellTag, \"r\") as fin:\n",
    "        with open(outfile, \"w\") as fout:\n",
    "            rfin = csv.reader(fin, delimiter=\",\")\n",
    "            wfout = csv.writer(fout, delimiter=\",\")\n",
    "            all_types = next(rfin)[1:]\n",
    "            cell_types = []\n",
    "            for row in rfin:\n",
    "                row_nu = [int(x) for x in row[1:]]\n",
    "                rowMax = max(row_nu)\n",
    "                rowSum = sum(row_nu)\n",
    "                row_type = all_types[row_nu.index(rowMax)]\n",
    "                if rowMax < float(rowSum)*0.7:\n",
    "                    #print('Error in cell %s, maximum hashtag reads less than 70 percent...' %row[0])\n",
    "                    #print(row)\n",
    "                    row_type = \"Ambigous\"\n",
    "                    \n",
    "                wfout.writerow([row_type])\n",
    "                cell_types.append(row_type)\n",
    "    types_set = list(set(cell_types))\n",
    "    print(\"Total cell number: %s\" %str(len(cell_types)))\n",
    "    print(\"-------------------\")\n",
    "    print(\"Ambigous percentage: %s\" %str(float(cell_types.count(\"Ambigous\"))*100/len(cell_types)))\n",
    "    print(\"-------------------\")\n",
    "    for i in types_set:\n",
    "        if i != \"Ambigous\":\n",
    "            print(\"%s percentage: %s\" %(i, str(float(cell_types.count(i))*100/len(cell_types))))\n",
    "    return(cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/pipkin/ROCKET-PRO/CD8_DEV_SC/Acute_Chronic/codes_local'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_dir = os.getcwd()\n",
    "base_dir = code_dir.replace(\"/codes_local\",\"\")\n",
    "wk_dir = base_dir + \"1_Scanpy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wk_dir = \"/Volumes/Yolanda/Exp391_Acute-Chronic_SC/1_Scanpy\"\n",
    "os.chdir(wk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cell number: 18353\n",
      "-------------------\n",
      "Ambigous percentage: 11.267912602844222\n",
      "-------------------\n",
      "NWT percentage: 5.094534953413611\n",
      "A8T percentage: 9.268239524873318\n",
      "A8P percentage: 7.110554132839318\n",
      "A5T percentage: 19.239361412303165\n",
      "A5P percentage: 20.53615212771754\n",
      "C5P percentage: 15.88296191358361\n",
      "C8P percentage: 5.900942625183894\n",
      "NP14B percentage: 5.699340707241323\n"
     ]
    }
   ],
   "source": [
    "ft_tsv = \"/Volumes/Yolanda/Exp391_Acute-Chronic_SC/1_0_cellranger_outs/filtered_feature_bc_matrix/features.tsv\"\n",
    "mtx_mtx = \"/Volumes/Yolanda/Exp391_Acute-Chronic_SC/1_0_cellranger_outs/filtered_feature_bc_matrix/matrix.mtx\"\n",
    "cellAbReads(ft_tsv, mtx_mtx)\n",
    "Exp391_celltypes = cellType(\"Cells_hashTags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
